{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mask R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Af9Ey8bWII"
      },
      "source": [
        "## TensorFlow 다운그레이드\n",
        "\n",
        "2.9.2 -> 2.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zkaHHv6jZpcY",
        "outputId": "c41fcb91-3eee-4569-8ff5-5d0e29e9e24b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJyXvVbaZc-a",
        "outputId": "bfbeba70-d9d5-498b-b0a0-7b5a32d778a0"
      },
      "outputs": [],
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
        "!dpkg -i libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb\n",
        "!ls -l /usr/lib/x86_64-linux-gnu/libcudnn.so.*\n",
        "!pip install -U -qq tensorflow==2.5.0\n",
        "exit() # 런타임 다시 시작 필요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "d9hl1f-3akGZ",
        "outputId": "b1259fee-0196-4134-a930-bc07c4f51dc8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "848MproXbraa",
        "outputId": "9ed688d4-e434-4e39-ead3-96878665f8d3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1c6q9tRxFTO",
        "outputId": "e735541c-0379-45ce-b970-7d19f32ca712"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu78d4rSbWIL"
      },
      "source": [
        "## Mask R-CNN 소스코드\n",
        "\n",
        "- Original: https://github.com/matterport/Mask_RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wUDJAUGb76s",
        "outputId": "3776fd51-1a90-4f37-c7ff-fdbab01921f3"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kairess/Mask_RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLln0VbzbWIL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "ROOT_DIR = 'Mask_RCNN'\n",
        "\n",
        "sys.path.append(ROOT_DIR)\n",
        "from mrcnn.config import Config\n",
        "import mrcnn.utils as utils\n",
        "from mrcnn import visualize\n",
        "import mrcnn.model as modellib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCRUELJ4bWIL"
      },
      "source": [
        "## 사전학습 모델 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-Jkhrh3bWIM",
        "outputId": "af218ae8-b222-44e2-b002-03b846353aa6"
      },
      "outputs": [],
      "source": [
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Ocrt7TbWIM"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "- NAME: weights, tensorboard 저장 폴더 이름\n",
        "- IMAGES_PER_GPU: 배치 사이즈\n",
        "- LEARNING_RATE\n",
        "- NUM_CLASSES: 학습할 클래스 개수 (배경 +1 필요)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbBlscctbWIM",
        "outputId": "a822480f-fcf4-44e0-e22f-9634b36b2a5d"
      },
      "outputs": [],
      "source": [
        "class TrainConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"custom\"\n",
        "\n",
        "    # Train on 1 GPU and 1 image per GPU. Batch size is 1 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 5\n",
        "\n",
        "    LEARNING_RATE = 0.001\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 2  # background + 2 (red, green)\n",
        "\n",
        "    # All of our training images are 1920x1012\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "\n",
        "    # Matterport originally used resnet101, but I downsized to fit it on my graphics card\n",
        "    BACKBONE = 'resnet50' # resnet50\n",
        "\n",
        "    # To be honest, I haven't taken the time to figure out what these do\n",
        "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    MAX_GT_INSTANCES = 50\n",
        "    POST_NMS_ROIS_INFERENCE = 500\n",
        "    POST_NMS_ROIS_TRAINING = 1000\n",
        "\n",
        "config = TrainConfig()\n",
        "config.display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkLinXQ4bWIO"
      },
      "source": [
        "## Define the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "J4HwBJYybWIO"
      },
      "outputs": [],
      "source": [
        "class CocoLikeDataset(utils.Dataset):\n",
        "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n",
        "        See http://cocodataset.org/#home for more information.\n",
        "    \"\"\"\n",
        "    def load_data(self, annotation_json, images_dir):\n",
        "        \"\"\" Load the coco-like dataset from json\n",
        "        Args:\n",
        "            annotation_json: The path to the coco annotations json file\n",
        "            images_dir: The directory holding the images referred to by the json file\n",
        "        \"\"\"\n",
        "        # Load json from file\n",
        "        json_file = open(annotation_json)\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "\n",
        "        # Add the class names using the base method from utils.Dataset\n",
        "        source_name = \"coco_like\"\n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['id']\n",
        "            class_name = category['name']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n",
        "                return\n",
        "\n",
        "            self.add_class(source_name, class_id, class_name)\n",
        "\n",
        "        # Get all annotations\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "\n",
        "        # Get all images and add them to the dataset\n",
        "        seen_images = {}\n",
        "        for image in coco_json['images']:\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "\n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
        "                image_annotations = annotations[image_id]\n",
        "\n",
        "                # Add the image using the base method from utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Load instance masks for the given image.\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
        "        Args:\n",
        "            image_id: The id of the image to load masks for\n",
        "        Returns:\n",
        "            masks: A bool array of shape [height, width, instance count] with\n",
        "                one mask per instance.\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "\n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "\n",
        "        return mask, class_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bJ2sgFmbWIP"
      },
      "source": [
        "## Create the Training and Validation Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "collapsed": true,
        "id": "ZBr_RN3jbWIP",
        "outputId": "90413064-10af-4a81-dd71-a548a83ab369"
      },
      "outputs": [],
      "source": [
        "dataset_train = CocoLikeDataset()\n",
        "dataset_train.load_data('dataset/train.json', 'dataset/train/')\n",
        "dataset_train.prepare()\n",
        "\n",
        "dataset_val = CocoLikeDataset()\n",
        "dataset_val.load_data('dataset/val.json', 'dataset/val/')\n",
        "dataset_val.prepare()\n",
        "\n",
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "\n",
        "print('Train', len(dataset_train.image_ids))\n",
        "print('Validation', len(dataset_val.image_ids))\n",
        "\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8fgtO0YbWIQ"
      },
      "source": [
        "## Create the Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "21kI-GDVbWIQ",
        "outputId": "2ec40eb4-7791-4531-e218-408dfd0f8719"
      },
      "outputs": [],
      "source": [
        "model = modellib.MaskRCNN(\n",
        "    mode=\"training\",\n",
        "    config=config,\n",
        "    model_dir=MODEL_DIR)\n",
        "\n",
        "model.load_weights(\n",
        "    COCO_MODEL_PATH,\n",
        "    by_name=True,\n",
        "    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfjOoFv6bWIR"
      },
      "source": [
        "## Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rIdp9nNdU15"
      },
      "source": [
        "### 1. Head Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psHJuASJbWIR",
        "outputId": "df854cfc-5342-4618-ccf1-bfde45937847",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "start_train = time.time()\n",
        "\n",
        "model.train(\n",
        "    dataset_train,\n",
        "    dataset_val,\n",
        "    learning_rate=config.LEARNING_RATE,\n",
        "    epochs=10,\n",
        "    layers='heads')\n",
        "\n",
        "end_train = time.time()\n",
        "minutes = round((end_train - start_train) / 60, 2)\n",
        "\n",
        "print(f'Training took {minutes} minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEXaaa4hdcvv"
      },
      "source": [
        "### 2. All layers\n",
        "\n",
        "Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulHLTLG2bWIR",
        "outputId": "2a33e51c-1ee7-495a-93ee-6aa8abbe9dfe",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Fine tune all layers\n",
        "# Passing layers=\"all\" trains all layers. You can also\n",
        "# pass a regular expression to select which layers to\n",
        "# train by name pattern.\n",
        "start_train = time.time()\n",
        "\n",
        "model.train(\n",
        "    dataset_train,\n",
        "    dataset_val,\n",
        "    learning_rate=config.LEARNING_RATE / 10,\n",
        "    epochs=15,\n",
        "    layers=\"all\")\n",
        "\n",
        "end_train = time.time()\n",
        "minutes = round((end_train - start_train) / 60, 2)\n",
        "\n",
        "print(f'Training took {minutes} minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5fqyV4JbWIS"
      },
      "source": [
        "## Prepare to run Inference\n",
        "\n",
        "Create a new InferenceConfig, then use it to create a new model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LPCWHRzVbWIS",
        "outputId": "f3e504c2-f163-4888-ec3b-6258e88996a4"
      },
      "outputs": [],
      "source": [
        "class InferenceConfig(TrainConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0.85\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "test_model = modellib.MaskRCNN(\n",
        "    mode=\"inference\",\n",
        "    config=inference_config,\n",
        "    model_dir=MODEL_DIR)\n",
        "\n",
        "model_path = test_model.find_last()\n",
        "print(model_path)\n",
        "\n",
        "test_model.load_weights(model_path, by_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7gqXdmkukbq"
      },
      "source": [
        "## 동영상 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-4p2OFVghBeE",
        "outputId": "d6c3929e-691d-4754-e8e9-122955c2d735"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab import files\n",
        "\n",
        "mask_colors_255 = [\n",
        "    (0, 0, 0), # Background\n",
        "    (0, 0, 255), # Red\n",
        "    (0, 255, 0)  # Green\n",
        "]\n",
        "\n",
        "cap = cv2.VideoCapture('Mask_RCNN/assets/video.mov')\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, img = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = test_model.detect([img])\n",
        "\n",
        "    rois = results[0]['rois']\n",
        "    class_ids = results[0]['class_ids']\n",
        "    scores = results[0]['scores']\n",
        "    masks = results[0]['masks']\n",
        "\n",
        "    result_img = img.copy()\n",
        "\n",
        "    for i, class_id in enumerate(class_ids):\n",
        "        mask = masks[:, :, i].astype(np.float32)\n",
        "        mask = (mask * 255).astype(np.uint8)\n",
        "\n",
        "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        cv2.drawContours(result_img, contours, 0, mask_colors_255[class_id], 2)\n",
        "\n",
        "        x, y, w, h = cv2.boundingRect(contours[0])\n",
        "        # cv2.rectangle(result_img, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
        "\n",
        "        # convert from pixel to mm\n",
        "        ## 10 px = 1 cm\n",
        "        ratio = 1 / 10\n",
        "        cm = int(h * ratio)\n",
        "        cv2.putText(result_img, f'{cm}cm', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)\n",
        "\n",
        "    out.write(result_img)\n",
        "\n",
        "out.release()\n",
        "\n",
        "files.download('output.mp4')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
